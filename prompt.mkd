# ECOBUDGET-CAB  Plan d'implémentation

## Objectif

Construire un outil local (RGPD-friendly) pour :

- extraire les lignes de devis PDF (texte & tableaux),
- identifier automatiquement les lignes éligibles au  budget vert  (dépenses favorables au climat / biodiversité),
- permettre la validation humaine et produire des exports Excel/CSV.

## Contraintes principales

- Exécution 100 % locale  Ollama retenu pour l'analyse IA (pas de fuite de données).
- Coût opérationnel faible, maintien par la DSI locale.
- Interface simple pour validation humaine et export pour la comptabilité.

## Arborescence recommandée

ECOBUDGET-CAB-Communaut-d'Agglomeration-du-Boulonnais/

- backend/
  - app/
    - main.py
    - routers/upload.py
    - services/
      - pdf_extractor.py
      - llm_classifier_ollama.py
      - budget_vert_taxonomy.py
    - core/config.py
  - requirements.txt

- frontend/ (React + Vite + TypeScript)
  - src/
    - components/ (UploadZone, DevisTable, ClassificationBadge)
    - pages/ (Home, DevisDetail)
    - services/api.ts
    - App.tsx
  - vite.config.ts

- data/
  - taxonomie_budget_vert_cab.json
  - exemples_devis_anonymises/

- .env.example
- docker-compose.yml
- README.md

## Choix techniques (résumé)

- Backend : FastAPI (Python).
- IA locale : Ollama  modèles en local, RGPD-friendly.
- Extraction PDF/OCR : pdfplumber + PyMuPDF ; Tesseract en fallback.
- Frontend : React + Vite + TypeScript (+ Tailwind pour la UI).
- Base : SQLite en dev, PostgreSQL en production.

## Roadmap (synthèse)

### Semaine 1–2 — Socle technique

- Initialiser backend FastAPI, frontend Vite, CORS/proxy et upload.

### Semaine 3–4 — Extraction

- Extraire texte/tableaux (pdfplumber). Fallback OCR si besoin (Tesseract).
- Normaliser lignes (désignation, montant HT).

### Semaine 5–7 — Classification IA

- Définir taxonomie (JSON/Excel).
- Construire prompts/few-shot, intégrer Ollama.

### Semaine 8–10 — Interface & validation

- Tableau éditable, correction manuelle, historique et export Excel.

### Semaine 11–12 — Production

- Statistiques, comparatifs annuels, intégrations d'export.
- Export Excel final avec 2 onglets (Total + Budget Vert) et formules de contrôle (somme/autocheck) — validé par la compta.
 Historique des devis traités stocké en SQLite (traçabilité exigée par RGPD).
- Bouton "Valider et transmettre à Astre/Ciril" → génère CSV au format du logiciel financier (préparation transmission comptable).

## Exemple de taxonomie (data/taxonomie_budget_vert_cab.json)
 
 Règles :
 
 Si doute → budget_vert = false.
 Exclure dépenses non-vertes (ex. : climatisation, gazon synthétique, carburants, éclairage halogène, véhicules thermiques).
  "version": "2025-CAB",
  "categories": [
    {"code": "V1", "nom": "Performance énergétique bâtiments", "mots_cles": ["isolation","pompe à chaleur","chaudière biomasse","rénovation thermique","LED"]},
    {"code": "V2", "nom": "Mobilité douce & décarbonée", "mots_cles": ["vélo","piste cyclable","borne IRVE","véhicule électrique"]},
    {"code": "V3", "nom": "Biodiversité & adaptation", "mots_cles": ["plantation","désimperméabilisation","gestion différenciée"]}
  ],
  "exclusions": ["climatisation","gazon synthétique","éclairage halogène","carburant"]
}

## Prompt  format de sortie (JSON strict)

SYSTEM_PROMPT (exemple) :

Tu es un agent comptable expert du budget vert de la Communauté d’Agglomération du Boulonnais.
Tu appliques la méthodologie nationale 2025 (Ademe/I4CE) + les règles spécifiques CAB.

Règles ABSOLUES :
- Doute → budget_vert = false
- Exclure systématiquement : climatisation, gazon synthétique, véhicules thermiques, éclairage non LED, désherbant chimique, carburant
- N’inclure que les dépenses DIRECTEMENT favorables au climat OU à la biodiversité

Réponds EXACTEMENT avec une liste JSON (rien d’autre, pas de ```json) :

[
  {"ligne":"Isolation extérieure 200mm","montant_ht":15420.00,"budget_vert":true,"code_categorie":"V1","confiance":0.98,"explication":"Rénovation thermique performante"},
  {"ligne":"Climatisation réversible","montant_ht":8900.00,"budget_vert":false,"code_categorie":null,"confiance":1.00,"explication":"Refroidissement actif → exclus du budget vert"}
]

## Intégration Ollama — points pratiques

- Héberger Ollama localement (Docker), monter `./ollama_models` pour persistance.
- Envoyer le SYSTEM_PROMPT + lignes à classifier via l'API de chat d'Ollama.
- Valider strictement la sortie JSON côté backend avant ingestion.

## Extraits utilitaires

### docker-compose (extrait minimal)

```yaml
version: '3.9'
services:
  ollama:
    image: ollama/ollama:latest
    ports: ["11434:11434"]
    volumes: ["./ollama_models:/root/.ollama"]
    restart: unless-stopped

  backend:
    build: ./backend
    ports: ["8000:8000"]
    depends_on: [ollama]
    volumes: ["./backend:/app","./data:/data"]
    environment: ["OLLAMA_HOST=http://ollama:11434"]
    restart: unless-stopped

  frontend:
    build: ./frontend
    ports: ["5173:5173"]
    depends_on: [backend]
    restart: unless-stopped
```

### Commandes (PowerShell)

```powershell
cd backend
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
uvicorn app.main:app --reload
```

```powershell
cd frontend
npm install
npm run dev
```

```powershell
docker-compose up --build
```


## Fichiers d'amorçage

Le plan décrit les fichiers à fournir pour un démarrage rapide : backend FastAPI, services d'extraction & classification (Ollama), frontend minimal, Dockerfiles et docker-compose.

## Prochaine étape recommandée

- Générer les fichiers de démarrage dans le dépôt et lancer un test local via Docker Compose.

---

## 📋 RÉSUMÉ DE L'AVANCEMENT (22 Nov 2025)

### ✅ Ce qui a été accompli

#### Phase 1 : Socle technique (TERMINÉ ✅)

**Structure complète créée :**
- ✅ Backend FastAPI avec tous les fichiers de base
  - `backend/app/main.py` : API avec CORS configuré pour VPS (168.231.77.11:5173)
  - `backend/app/core/config.py` : Gestion des variables d'environnement
  - `backend/app/routers/upload.py` : Endpoint `/api/v1/upload` opérationnel
  - Services stubs créés : `pdf_extractor.py`, `llm_classifier_ollama.py`, `budget_vert_taxonomy.py`
  - `requirements.txt` : Dépendances (FastAPI, pdfplumber, pymupdf, httpx, etc.)

- ✅ Frontend React + Vite + TypeScript
  - Structure complète avec Tailwind CSS
  - `frontend/src/App.tsx` : Interface d'accueil
  - Configuration TypeScript stricte
  - PostCSS + Autoprefixer configurés

- ✅ Docker & Orchestration
  - `docker-compose.yml` : 3 services (Ollama sur port 11435, Backend 8000, Frontend 5173)
  - Dockerfiles pour backend et frontend
  - Volume persistant pour modèles Ollama

- ✅ Données
  - `data/taxonomie_budget_vert_cab.json` : Taxonomie budget vert avec 3 catégories (V1, V2, V3) et exclusions

#### Déploiement VPS (TERMINÉ ✅)

**VPS de test configuré (168.231.77.11) :**
- ✅ Code poussé sur GitHub : `jfcwebcraft/ECOBUDGET-CAB-Communaut-d-Agglomeration-du-Boulonnais`
- ✅ Clone et build réussi sur le VPS Ubuntu 24.04
- ✅ 3 conteneurs Docker actifs :
  - `ollama_1` : Service IA local (port 11435)
  - `backend_1` : API FastAPI (port 8000)
  - `frontend_1` : Interface React (port 5173)

**URLs opérationnelles :**
- Frontend : http://168.231.77.11:5173 ✅
- Backend API : http://168.231.77.11:8000/docs ✅

### 🚧 État actuel par rapport à la roadmap

| Phase | Statut | Détails |
|-------|--------|---------|
| **Semaine 1-2 : Socle technique** | ✅ **TERMINÉ** | Backend, Frontend, Docker, Taxonomie, Déploiement VPS |
| **Semaine 3-4 : Extraction** | ⏳ **À FAIRE** | `pdf_extractor.py` est un stub, pas d'implémentation pdfplumber |
| **Semaine 5-7 : Classification IA** | ⏳ **À FAIRE** | `llm_classifier_ollama.py` est un stub, Ollama sans modèle téléchargé |
| **Semaine 8-10 : Interface & validation** | ⏳ **À FAIRE** | Pas de composants d'upload, tableau, ni export Excel |
| **Semaine 11-12 : Production** | ⏳ **À FAIRE** | SQLite, statistiques, exports comptables à venir |

### 🎯 Prochaines étapes immédiates

#### 1. Préparation Ollama (Critique pour la classification)
```bash
# Sur le VPS
docker exec -it ecobudget-cab-communaut-d-agglomeration-du-boulonnais_ollama_1 ollama pull mistral
```

#### 2. Implémentation Extraction PDF (Semaine 3-4)
- Compléter `backend/app/services/pdf_extractor.py` avec pdfplumber
- Extraire texte et tableaux des devis PDF
- Normaliser les lignes (désignation, montant HT)
- Ajouter fallback OCR (Tesseract) si nécessaire

#### 3. Interface d'Upload (Semaine 8)
Créer dans `frontend/src/components/` :
- `UploadZone.tsx` : Zone de drag & drop pour PDF
- Connecter à l'endpoint `/api/v1/upload` existant
- Afficher le statut d'upload et les erreurs

#### 4. Classification IA (Semaine 5-7)
- Implémenter `llm_classifier_ollama.py` avec le SYSTEM_PROMPT défini
- Intégrer la taxonomie JSON
- Valider le format de sortie JSON strict
- Tests avec exemples de devis

### 📂 Fichiers clés créés

**Code source :**
- Backend : 10 fichiers Python (main, config, routers, services)
- Frontend : 12 fichiers TypeScript/React + config
- Infrastructure : 3 fichiers (docker-compose, Dockerfiles, .env.example)
- Données : 1 fichier JSON (taxonomie)

**Scripts utilitaires :**
- `deploy_vps.ps1` : Script de déploiement SSH (non utilisé finalement)
- `upload_helper.ps1` : Script d'upload vers services tiers (non utilisé finalement)
- **Méthode finale retenue** : Git clone depuis GitHub

**Documentation :**
- `README.md` : Guide de démarrage
- `.gemini/antigravity/brain/*/walkthrough.md` : Documentation détaillée du déploiement

### 🔧 Commandes de maintenance VPS

**Mettre à jour le code :**
```bash
cd /root/ECOBUDGET-CAB-Communaut-d-Agglomeration-du-Boulonnais
git pull origin main
docker-compose down
docker-compose up -d --build
```

**Voir les logs :**
```bash
docker logs -f ecobudget-cab-communaut-d-agglomeration-du-boulonnais_backend_1
docker logs -f ecobudget-cab-communaut-d-agglomeration-du-boulonnais_frontend_1
```

### 💡 Notes importantes

- Le port Ollama a été changé de 11434 → 11435 pour éviter les conflits avec l'instance Ollama existante sur le VPS
- Le VPS héberge déjà d'autres projets (AnythingLLM, n8n, Traefik, PostgreSQL, etc.)
- Le dépôt GitHub a été temporairement rendu public pour faciliter le clone initial
- CORS configuré pour accepter les requêtes depuis l'IP du VPS

### 🎓 Leçons apprises durant le déploiement

1. **SSH bloqué** : Connexion refusée malgré le bon mot de passe → solution Git clone HTTPS
2. **Services d'upload bloqués** : transfer.sh et file.io inaccessibles → solution GitHub
3. **Importance de la persistance** : Volume `ollama_models` créé pour éviter de re-télécharger les modèles

---

## Prochaine étape recommandée

**Option A (Rapide - Test fonctionnel) :** Créer l'interface d'upload pour tester le flux complet sans IA

**Option B (Complet - Fondations solides) :** Implémenter l'extraction PDF pour avoir des données réelles à classifier

**Option C (IA d'abord) :** Télécharger Mistral et implémenter la classification, tester avec des données mock
